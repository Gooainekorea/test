{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kn1-utfvOYLcCi8ej4my1Y6M3XvPnp-T","timestamp":1741692178779}],"authorship_tag":"ABX9TyOJirahV61Rld4BBAlgooFD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install gradio tensorflow==2.12.0 opencv-python mediapipe\n","\n","import gradio as gr\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","import mediapipe as mp\n","from keras.models import load_model\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from PIL import Image, ImageOps\n","\n","# MobileNetV2 기반의 전이 학습 모델 사용\n","base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n","model = tf.keras.Sequential([\n","    base_model,\n","    tf.keras.layers.GlobalAveragePooling2D(),\n","    tf.keras.layers.Dense(128, activation=\"relu\"),\n","    tf.keras.layers.Dense(3, activation=\"softmax\")  # 가위, 바위, 보 (3개 클래스)\n","])\n","\n","# Mediapipe를 사용한 손 검출\n","mp_hands = mp.solutions.hands\n","hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n","\n","def preprocess_hand(image):\n","    \"\"\"OpenCV + Mediapipe를 이용하여 손 부분만 추출\"\"\"\n","    image_cv = np.array(image)\n","    image_rgb = cv2.cvtColor(image_cv, cv2.COLOR_RGB2BGR)\n","    results = hands.process(image_rgb)\n","\n","    if results.multi_hand_landmarks:\n","        for hand_landmarks in results.multi_hand_landmarks:\n","            x_min = min([lm.x for lm in hand_landmarks.landmark])\n","            y_min = min([lm.y for lm in hand_landmarks.landmark])\n","            x_max = max([lm.x for lm in hand_landmarks.landmark])\n","            y_max = max([lm.y for lm in hand_landmarks.landmark])\n","\n","            h, w, _ = image_cv.shape\n","            x_min, y_min, x_max, y_max = int(x_min * w), int(y_min * h), int(x_max * w), int(y_max * h)\n","\n","            image_cv = image_cv[y_min:y_max, x_min:x_max]\n","            break\n","\n","    return Image.fromarray(image_cv)\n","\n","# 예측 함수\n","def predict_rps(img):\n","    img = preprocess_hand(img)  # 손만 인식하도록 전처리\n","    img = img.resize((224, 224))\n","    img = np.array(img) / 255.0  # 정규화\n","    img = np.expand_dims(img, axis=0)\n","\n","    predictions = model.predict(img)\n","    predicted_class = np.argmax(predictions)\n","    confidence = predictions[0][predicted_class]\n","\n","    class_names = [\"가위\", \"바위\", \"보\"]\n","    return f\"{class_names[predicted_class]} (확률: {confidence:.2%})\"\n","\n","# Gradio UI\n","interface = gr.Interface(\n","    fn=predict_rps,\n","    inputs=gr.Image(type=\"pil\"),\n","    outputs=\"text\",\n","    title=\"가위바위보 인식기 (개선된 모델)\",\n","    description=\"실제 사진에서도 잘 인식되도록 개선한 모델입니다.\",\n",")\n","\n","# 실행\n","if __name__ == \"__main__\":\n","    interface.launch()\n"],"metadata":{"id":"VqURvsIG7-_J"},"execution_count":null,"outputs":[]}]}